# Transformer-based-LLM
I've documented and built a LLM using Transformer architecture referring the "all you need is attention" research paper
