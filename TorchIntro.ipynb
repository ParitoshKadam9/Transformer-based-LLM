{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f38bd1-31af-4c7a-8984-964c3a2c210a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import time \n",
    "import numpy as np\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743707c2-e1a6-43ea-afc4-990236a27c6e",
   "metadata": {},
   "source": [
    "## Basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "605a6335-7691-425d-b29f-39208031b22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1, -24,  32,   3, -27,  74])\n"
     ]
    }
   ],
   "source": [
    "randint = torch.randint(-100, 100, (6, ))\n",
    "print(randint)\n",
    "\n",
    "#Keeping this in mind for when we need BLOCKS for our BACTHES from our random CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e07a33-fa6f-468a-a77e-4f842abb43ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 1.2000],\n",
      "        [2.2000, 3.1000],\n",
      "        [4.9000, 5.2000]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n",
    "print(tensor)\n",
    "# we get a 3x2 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a08cb31-c7fb-4743-ada3-77327808d10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(2, 3)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "709f2aac-eec3-4383-a7be-f9be3e93fdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arange = torch.arange(5)\n",
    "arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93edb0c7-6c5c-4149-b884-240d45c9c91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.0000,  4.7500,  6.5000,  8.2500, 10.0000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linespace = torch.linspace(3, 10, steps=5)\n",
    "linespace\n",
    "\n",
    "#Arithmetic progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce6819df-fd89-4b2e-bb62-b47f6a3834a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logspace= torch.logspace(start=-10, end = 10, steps = 5)\n",
    "logspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b55797b3-9df9-43ff-8744-c148a44cd4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Basically an DIAGONAL matrix \n",
    "eye = torch.eye(5)\n",
    "eye "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8427161e-a288-464e-b85e-0ae7d9e6fb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.empty((2, 3), dtype=torch.int64)\n",
    "empty = torch.empty_like(a)\n",
    "empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a745db2-7c53-435d-b3a4-b900ed7c67b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "#PROBABILITIES\n",
    "\n",
    "prob = torch.tensor([0.2, 0.8])\n",
    "#40% chance of getting a 0, 60% chance of getting a 1\n",
    "sample = torch.multinomial(prob, num_samples=10, replacement = True)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58fe52c2-8c78-4074-bb36-0ee188503fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "#CONCAT\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3, 4])\n",
    "out = torch.cat((tensor, torch.tensor([5])), dim=0)\n",
    "print(out)\n",
    "\n",
    "# we will use this when we generating text given context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc7152d-dda1-49fc-af24-70108baa42b0",
   "metadata": {},
   "source": [
    "So basically it will be zero, the we use the prob distrubution to concat the first char, and then the next ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98a5e17c-7505-44f2-8b1e-3c6f18908ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "out = torch.tril(torch.ones(5, 5))\n",
    "print(out)\n",
    "#tril = triangle - lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9bc1c6-2486-41b4-a5ff-16065ac16f6c",
   "metadata": {},
   "source": [
    "This is imp. When we are trying to predict integers in a seq, we only know what is in the current history.\n",
    "In the above ex, suppose we have predicted a 1 and the rest we havent, then we predicted anotehr 1 and the rest 3 are left, so here we are talking in history. (predicting while knowing what the answer is, just like in an exam. Basically in history of your knowledge, which answers would you predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598abf01-217c-4831-8bbb-608d29bbe399",
   "metadata": {},
   "source": [
    "### Imp function : nn.Linear \n",
    "- builds a fully connected dense linear neural network with y = x*wT+b\n",
    "- W = weight matrix of size [out_features, in_features]\n",
    "- each row of W corresponds to weights associated with one neurom in each layer\n",
    "- b = bias vector of size [out_features] => it provides an offset to the linear transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f001211-cd7d-4791-b7c0-3a7b3fe5cfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9.4093,  2.5464, -3.6148], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "sample = torch.tensor([10., 10., 10.])\n",
    "linear = nn.Linear(3, 3, bias = False)\n",
    "##the parameters are (output dimensions, input dimensions)\n",
    "print(linear(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa4b31b1-9f25-48f2-867a-4fcca7cd3af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "# SOFTMAX FUNCITON (basic) = exp(x)/sum(exp(x))\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tensor1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "softmax_output = F.softmax(tensor1, dim=0)\n",
    "\n",
    "print(softmax_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a83a3-52aa-42e8-b830-08abc7973e7d",
   "metadata": {},
   "source": [
    "## Embedding Vector\n",
    "\n",
    "Also known as embeddings - ***Type of numerical representation***\n",
    "\n",
    "- Fundamental technique for converting categorical data such as words as discrete items, into continuous vectors\n",
    "- Categorical data in its raw form cannot be directly used as input for most ML algorithms, especially NNs, hence.\n",
    "- Unlike hot-encoding, where each category is represented as binary vector, embedding vectors are dense and continuous\n",
    "- Embeddings assign each category a vector of floating-point numbers.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "56c2880c-719b-4492-98ba-5dc012d9e37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = 2600\n",
    "embedding_dim = 100\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "input_indices = torch.LongTensor([1, 5, 3, 2])\n",
    "\n",
    "embedded_output = embedding(input_indices)\n",
    "\n",
    "print(embedded_output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ec91fd-21cd-41ed-a622-0539ee70ad90",
   "metadata": {},
   "source": [
    "## Dot product and Matrix Multiplication\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "da0ed2a0-d96e-4103-a909-30b13cf3f546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3,4], [5, 6]])\n",
    "b = torch.tensor([[7,8,9], [10, 11, 12]])\n",
    "\n",
    "print(a @ b)\n",
    "print(torch.matmul(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a4444-6e40-4c27-a73d-f68f06d9e4a5",
   "metadata": {},
   "source": [
    "## Messing around with the GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5cc1589-83e1-4ab0-8782-5e8abf43cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Performance mesure\n",
    "\n",
    "start_time = time.time()\n",
    "#matix ops\n",
    "zeros = torch.zeros(100, 100)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time -start_time\n",
    "print(f\"{elapsed_time : 8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04e4c39a-6efd-4121-8760-ab0523cf0d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.02500033 GPU\n",
      "0.14006114 CPU\n"
     ]
    }
   ],
   "source": [
    "# numpy on CPU and torch on CUDA\n",
    "\n",
    "torch_rand1 = torch.rand(100, 100, 100, 100).to(device)\n",
    "torch_rand2 = torch.rand(100, 100, 100, 100).to(device)\n",
    "np_rand1 = torch.rand(100, 100, 100, 100)\n",
    "np_rand2 = torch.rand(100, 100, 100, 100)\n",
    "\n",
    "start_time = time.time()\n",
    "rand = (torch_rand1 @ torch_rand2)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time: .8f}\", \"GPU\")\n",
    "\n",
    "start_time = time.time()\n",
    "rand = np.multiply(np_rand1, np_rand2)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time-start_time\n",
    "print(f\"{elapsed_time:.8f}\", \"CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8be85b-3e8e-4186-a59e-958ceb32c55c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
